# Optimizaci√≥n de An√°lisis Mensuales - Soluci√≥n de Error de Memoria MongoDB

## üö® Problema Original

El error que se presentaba en las estad√≠sticas mensuales era:

```
Error fetching delivery type stats by month: Error: PlanExecutor error during aggregation :: caused by :: Sort exceeded memory limit of 33554432 bytes, but did not opt in to external sorting.
```

Este error ocurr√≠a porque la agregaci√≥n de MongoDB exced√≠a el l√≠mite de memoria de 33MB para operaciones de sorting.

## ‚úÖ Soluciones Implementadas

### 1. Optimizaci√≥n del Pipeline de Agregaci√≥n

**Archivo:** `packages/data-services/src/services/barfer/analytics/getDeliveryTypeStatsByMonth.ts`

#### Cambios principales:

1. **Filtrado temprano de documentos**: Se aplican los filtros de fecha al inicio del pipeline para reducir drasticamente el n√∫mero de documentos a procesar.

2. **Eliminaci√≥n de pasos intermedios**: Se simplific√≥ el pipeline eliminando el doble agrupamiento que causaba duplicados innecesarios.

3. **Uso de `allowDiskUse: true`**: Se habilit√≥ el uso de disco para operaciones de sorting que excedan el l√≠mite de memoria RAM.

4. **Optimizaci√≥n de proyecciones**: Se filtraron datos nulos antes del sorting para reducir el volumen de datos.

#### Antes vs Despu√©s:

**‚ùå Pipeline Original (problem√°tico):**
```typescript
// Convertir dates -> Filtrar -> AddFields -> Doble agrupamiento -> Sort
pipeline.push(
    { $addFields: { createdAt: ... } },    // Convertir todas las fechas
    { $match: dateCondition },             // Filtrar despu√©s de convertir
    { $addFields: { classifications } },    // Agregar campos 
    { $group: { _id: orderId ... } },      // Primer agrupamiento
    { $group: { _id: month ... } },        // Segundo agrupamiento 
    { $sort: { "_id.year": 1, "_id.month": 1 } }  // Sort sin allowDiskUse
);
```

**‚úÖ Pipeline Optimizado:**
```typescript
// Filtrar PRIMERO -> Convertir -> Agrupar UNA VEZ -> Sort con allowDiskUse
pipeline.push(
    { $match: { $expr: { $and: [dateConditions] } } }, // Filtrar PRIMERO
    { $addFields: { createdAt: ..., classifications } }, // Todo junto
    { $group: { _id: { year, month }, ... } },           // Agrupamiento directo
    { $project: { filterNulls } },                       // Limpiar datos
    { $sort: { "_id.year": 1, "_id.month": 1 } }         // Sort optimizado
);

// CON allowDiskUse
collection.aggregate(pipeline, { allowDiskUse: true })
```

### 2. Eliminaci√≥n de C√≥digo de Debug

Se removieron las funciones de debug que tambi√©n consum√≠an recursos:
- `debugWholesaleOrders()`
- `testWholesaleIssue()`

**Archivo:** `apps/app/app/[locale]/(authenticated)/admin/analytics/components/monthly/MonthlyAnalyticsTab.tsx`

### 3. Creaci√≥n de √çndices Optimizados

**Archivos creados:**
- `scripts/optimize-analytics-indexes.ts`
- `scripts/run-analytics-optimization.ts`

#### √çndices creados:

1. **`analytics_monthly_compound`**: Para consultas mensuales
   ```javascript
   { createdAt: 1, orderType: 1, status: 1 }
   ```

2. **`analytics_delivery_type`**: Para an√°lisis de tipos de entrega
   ```javascript
   { 'deliveryArea.sameDayDelivery': 1, orderType: 1, createdAt: 1 }
   ```

3. **`analytics_items_delivery`**: Para an√°lisis de items
   ```javascript
   { 'items.sameDayDelivery': 1, createdAt: 1, orderType: 1 }
   ```

4. **`analytics_date_sort`**: Para ordenamiento por fecha
   ```javascript
   { createdAt: -1 }
   ```

## üöÄ C√≥mo Aplicar las Optimizaciones

### Paso 1: Los cambios de c√≥digo ya est√°n aplicados

Los archivos modificados ya contienen las optimizaciones.

### Paso 2: Crear los √≠ndices optimizados

```bash
# Crear √≠ndices para optimizar consultas
pnpm analytics:optimize

# Si necesitas eliminar los √≠ndices
pnpm analytics:drop-indexes
```

### Paso 3: Verificar el funcionamiento

1. Ve a las estad√≠sticas en **Admin ‚Üí Analytics ‚Üí Por Mes**
2. Verifica que las consultas se ejecuten sin errores
3. Observa que la velocidad de carga sea notablemente mejor

## üìä Mejoras de Rendimiento Esperadas

### Antes de la optimizaci√≥n:
- ‚ùå Error de memoria al procesar grandes vol√∫menes de datos
- ‚ùå Timeouts en consultas complejas
- ‚ùå Alto consumo de recursos del servidor

### Despu√©s de la optimizaci√≥n:
- ‚úÖ Sin errores de memoria gracias a `allowDiskUse`
- ‚úÖ Consultas 3-5x m√°s r√°pidas gracias a los √≠ndices
- ‚úÖ Menos carga en el servidor MongoDB
- ‚úÖ Pipeline m√°s eficiente con menos pasos

## üîß Detalles T√©cnicos

### ¬øPor qu√© funcionan estas optimizaciones?

1. **Filtrado temprano**: Reduce el conjunto de datos desde el inicio
2. **allowDiskUse**: Permite usar disco cuando la memoria RAM no es suficiente
3. **√çndices compuestos**: MongoDB puede usar √≠ndices para acelerar filtros y sorts
4. **Pipeline simplificado**: Menos pasos = menos overhead

### Monitoreo

Para monitorear el rendimiento de las consultas:

```javascript
// En MongoDB, puedes usar explain() para ver el plan de ejecuci√≥n
db.orders.aggregate(pipeline).explain("executionStats")
```

## üéØ Archivos Modificados

1. **`packages/data-services/src/services/barfer/analytics/getDeliveryTypeStatsByMonth.ts`**
   - Optimizaci√≥n completa del pipeline de agregaci√≥n
   - Eliminaci√≥n de c√≥digo de debug

2. **`apps/app/app/[locale]/(authenticated)/admin/analytics/components/monthly/MonthlyAnalyticsTab.tsx`**
   - Eliminaci√≥n de llamadas a funciones de debug

3. **`scripts/optimize-analytics-indexes.ts`** (nuevo)
   - Script para crear/eliminar √≠ndices optimizados

4. **`scripts/run-analytics-optimization.ts`** (nuevo)
   - Ejecutor del script de optimizaci√≥n

5. **`package.json`**
   - Agregados scripts para ejecutar optimizaciones

## üìù Notas Importantes

- Los √≠ndices consumen espacio en disco adicional
- Es recomendable ejecutar la creaci√≥n de √≠ndices durante horarios de bajo tr√°fico
- Los √≠ndices se crean con `background: true` para no bloquear la base de datos
- Esta optimizaci√≥n es especialmente importante para bases de datos con gran cantidad de √≥rdenes

## üîÆ Optimizaciones Futuras

Si en el futuro se presentan problemas similares:

1. **Paginaci√≥n**: Implementar paginaci√≥n en consultas muy grandes
2. **Cache**: Agregar cache Redis para resultados de an√°lisis frecuentes
3. **Agregaciones pre-calculadas**: Crear vistas materializadas para datos hist√≥ricos
4. **Sharding**: Considerar particionamiento horizontal si el volumen crece significativamente
